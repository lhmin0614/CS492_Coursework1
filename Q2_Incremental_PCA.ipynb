{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2 Incremental PCA",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeQiY0Yeh3MxNYap26iyTF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lhmin0614/CS492_Coursework1/blob/main/Q2_Incremental_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJepdwudPdWG",
        "outputId": "d89d0548-4ac1-4a34-e312-f34d9354d274"
      },
      "source": [
        "%tensorflow_version 2.0x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.ndimage as ndimage\n",
        "import time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "mat = loadmat('/content/drive/MyDrive/CS492_teamProject/face.mat')\n",
        "\n",
        "X = mat['X']\n",
        "y = mat['l'][0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.0x`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR0DgBJDOvfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acdb10f-012f-4426-fdb2-ec6c318709b6"
      },
      "source": [
        "#train/test split\n",
        "train_X1 = [i[[True, False, False, False, False]*104] for i in X] \n",
        "train_X2 = [i[[False, True, False, False, False]*104] for i in X]\n",
        "train_X3 = [i[[False, False, True, False, False]*104] for i in X]\n",
        "train_X4 = [i[[False, False, False, True, False]*104] for i in X]\n",
        "test_X   = [i[[False, False, False, False, True]*104] for i in X]\n",
        "train_y = y[[True, True, True, True, False]*104]\n",
        "test_y  = y[[False, False, False, False, True]*104]\n",
        "\n",
        "print(\"<<Data dimension>>\")\n",
        "print(\"train_X1~4 : \", len(train_X1),\" * \", len(train_X1[0]))\n",
        "print(\"test_X  : \", len(test_X),\" * \",  len(test_X[0]))\n",
        "print(\"train_y : \", len(train_y))\n",
        "print(\"test_y  : \", len(test_y))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<Data dimension>>\n",
            "train_X1~4 :  2576  *  104\n",
            "test_X  :  2576  *  104\n",
            "train_y :  416\n",
            "test_y  :  104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA7yTYW2Pu-_"
      },
      "source": [
        "def pca(X, d):\n",
        "  N = len(X)\n",
        "  avg_X = [ sum(i)/len(i) for i in X ]   \n",
        "  sub_X = [ list(np.asarray(x) - x_bar) for x, x_bar in zip(X, avg_X) ]\n",
        "  A = np.matrix(sub_X)\n",
        "  S = np.dot(A, A.T)\n",
        "  eigvals, eigvecs_column = np.linalg.eigh(S)  \n",
        "  P = eigvecs_column.T[-d:].T\n",
        "  Lambda = np.diag(eigvals[-d:])\n",
        "\n",
        "  return (np.array(avg_X), N, P, Lambda, S)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im8MBtxrWdDr"
      },
      "source": [
        "def IPCA(d):\n",
        "\n",
        "  avg1, N1, P1, L1, S1 = pca(train_X1, d)\n",
        "\n",
        "  for train_X in [train_X2, train_X3, train_X4]:\n",
        "    avg2, N2, P2, L2, S2 = pca(train_X, d)\n",
        "    \n",
        "    #find combined mean\n",
        "    N3 = N1+N2\n",
        "    avg3 = (N1*avg1 + N2*avg2)/N2\n",
        "\n",
        "    #find conbined matrix\n",
        "    S3 = S1*N1/N3 + S2*N2/N3 + N1*N2*np.dot(np.matrix(avg1-avg2), np.matrix(avg1-avg2).T)/N3 \n",
        "\n",
        "    #find Phi\n",
        "    Phi = gs(np.concatenate((np.concatenate((P1,P2), axis=1),np.matrix(avg1-avg2).T), axis=1))\n",
        "\n",
        "    #decomposition\n",
        "    eigenproblem = np.dot(np.dot(Phi.T, S3),Phi)\n",
        "    start = time.time()\n",
        "    eigvals, R = np.linalg.eigh(eigenproblem)  \n",
        "    stop = time.time()\n",
        "    print(f\"Training time: {stop - start}s\")\n",
        "    L3 = np.diag(eigvals)             # d1+d2+1 eigvals\n",
        "\n",
        "    #prepare next step\n",
        "    avg1 = avg3\n",
        "    N1   = N3\n",
        "    P1   = np.dot(Phi, R)\n",
        "    L1   = L3\n",
        "    S1   = S3\n",
        "  \n",
        "  return avg1, N1, P1, L1, S1\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjibB74Mq7TX"
      },
      "source": [
        "def projection(X, avg_X, P) :\n",
        "  A = np.matrix([ list(np.asarray(x) - x_bar) for x, x_bar in zip(X, avg_X) ])\n",
        "  W = np.dot(A.T, P)\n",
        "  return W"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SniYxKGQux64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cad217-4f7d-42c1-ad59-e7547ada51d7"
      },
      "source": [
        "d_cand = [10, 20, 30, 40]\n",
        "\n",
        "for d_ in d_cand:\n",
        "  print(\"\\n\\nIncremental PCA for \"+ str(d_))\n",
        "  avg_, N_, P_, L_, S_ = IPCA(d_)\n",
        "  train_X  = [i[[True, True, True, True, False]*104] for i in X]\n",
        "  prj_X  = projection(train_X, avg_, P_)\n",
        "  validation_X = projection(test_X, avg_, P_)\n",
        "\n",
        "  #kNN accuracy\n",
        "  print(\"\\nprint accuracy train / test\")\n",
        "\n",
        "  for i in range(7):\n",
        "    classifier = KNeighborsClassifier(n_neighbors = i*2+1)\n",
        "    classifier.fit(prj_X.tolist(), train_y)\n",
        "\n",
        "    score_train = classifier.score(prj_X.tolist(), train_y)\n",
        "    score_test = classifier.score(validation_X.tolist(), test_y)\n",
        "\n",
        "    print(\"k=\"+str(i*2+1)+\" : \" +str(score_train) + \"/\" + str(score_test))\n",
        "  \n",
        "  #reconstruction error\n",
        "  avg_X = [ sum(i)/len(i) for i in train_X ]\n",
        "\n",
        "  sub_X = [ list(np.asarray(x) - x_bar) for x, x_bar in zip(train_X, avg_X) ]\n",
        "  A = np.matrix(sub_X)\n",
        "  W = np.dot(A.T, P_)\n",
        "  X_weighted_sum = np.dot(W, P_.T)\n",
        "\n",
        "  X_reconst = [list(np.asarray(x) + x_bar) for x, x_bar in zip(X_weighted_sum.tolist(), avg_X) ]\n",
        "\n",
        "  reconst_err = [np.linalg.norm(i-j) for i, j in zip(X_reconst, np.asarray(np.matrix(train_X).T))]\n",
        "  reconst_err_avg = sum(reconst_err)/len(reconst_err)\n",
        "\n",
        "  print(\"\\naverage reconstruction error is \" + str(reconst_err_avg))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Incremental PCA for 10\n",
            "Training time: 0.00036454200744628906s\n",
            "Training time: 0.0005018711090087891s\n",
            "Training time: 0.0008230209350585938s\n",
            "\n",
            "print accuracy train / test\n",
            "k=1 : 1.0/0.7019230769230769\n",
            "k=3 : 0.6490384615384616/0.5769230769230769\n",
            "k=5 : 0.6009615384615384/0.5288461538461539\n",
            "k=7 : 0.5384615384615384/0.4519230769230769\n",
            "k=9 : 0.4951923076923077/0.49038461538461536\n",
            "k=11 : 0.43990384615384615/0.40384615384615385\n",
            "k=13 : 0.40625/0.375\n",
            "\n",
            "average reconstruction error is 1822.0884335968576\n",
            "\n",
            "\n",
            "Incremental PCA for 20\n",
            "Training time: 0.0007715225219726562s\n",
            "Training time: 0.0012574195861816406s\n",
            "Training time: 0.0018393993377685547s\n",
            "\n",
            "print accuracy train / test\n",
            "k=1 : 1.0/0.7307692307692307\n",
            "k=3 : 0.6658653846153846/0.5480769230769231\n",
            "k=5 : 0.6298076923076923/0.5192307692307693\n",
            "k=7 : 0.5576923076923077/0.4519230769230769\n",
            "k=9 : 0.4951923076923077/0.4807692307692308\n",
            "k=11 : 0.4495192307692308/0.4230769230769231\n",
            "k=13 : 0.42788461538461536/0.36538461538461536\n",
            "\n",
            "average reconstruction error is 1719.1609555504326\n",
            "\n",
            "\n",
            "Incremental PCA for 30\n",
            "Training time: 0.0011336803436279297s\n",
            "Training time: 0.002099752426147461s\n",
            "Training time: 0.0030736923217773438s\n",
            "\n",
            "print accuracy train / test\n",
            "k=1 : 1.0/0.7211538461538461\n",
            "k=3 : 0.6899038461538461/0.5673076923076923\n",
            "k=5 : 0.6394230769230769/0.5576923076923077\n",
            "k=7 : 0.5600961538461539/0.4423076923076923\n",
            "k=9 : 0.5/0.4423076923076923\n",
            "k=11 : 0.44711538461538464/0.4230769230769231\n",
            "k=13 : 0.44471153846153844/0.3557692307692308\n",
            "\n",
            "average reconstruction error is 1667.124809482865\n",
            "\n",
            "\n",
            "Incremental PCA for 40\n",
            "Training time: 0.0017998218536376953s\n",
            "Training time: 0.003027677536010742s\n",
            "Training time: 0.005095720291137695s\n",
            "\n",
            "print accuracy train / test\n",
            "k=1 : 1.0/0.75\n",
            "k=3 : 0.6923076923076923/0.5673076923076923\n",
            "k=5 : 0.6298076923076923/0.5\n",
            "k=7 : 0.5625/0.46153846153846156\n",
            "k=9 : 0.4879807692307692/0.4423076923076923\n",
            "k=11 : 0.45913461538461536/0.4326923076923077\n",
            "k=13 : 0.4543269230769231/0.375\n",
            "\n",
            "average reconstruction error is 1633.1905909687632\n"
          ]
        }
      ]
    }
  ]
}